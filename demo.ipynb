{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UGATIT import UGATIT\n",
    "import argparse\n",
    "from glob import glob\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"parsing and configuration\"\"\"\n",
    "\n",
    "def parse_args():\n",
    "    desc = \"Pytorch implementation of U-GAT-IT\"\n",
    "    parser = argparse.ArgumentParser(description=desc)\n",
    "    parser.add_argument('--phase', type=str, default='train', help='[train / test]')\n",
    "#     parser.add_argument('--light', type=str2bool, default=True, help='[U-GAT-IT full version / U-GAT-IT light version]')\n",
    "    parser.add_argument('--light', type=str2bool, default=False, help='[U-GAT-IT full version / U-GAT-IT light version]')\n",
    "    parser.add_argument('--dataset', type=str, default='selfie2anime', help='dataset_name')\n",
    "\n",
    "    parser.add_argument('--iteration', type=int, default=1000000, help='The number of training iterations')\n",
    "    parser.add_argument('--batch_size', type=int, default=1, help='The size of batch size')\n",
    "    parser.add_argument('--print_freq', type=int, default=10, help='The number of image print freq')\n",
    "    parser.add_argument('--save_freq', type=int, default=10, help='The number of model save freq')\n",
    "    parser.add_argument('--decay_flag', type=str2bool, default=True, help='The decay_flag')\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=0.0001, help='The learning rate')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0001, help='The weight decay')\n",
    "    parser.add_argument('--adv_weight', type=int, default=1, help='Weight for GAN')\n",
    "    parser.add_argument('--cycle_weight', type=int, default=10, help='Weight for Cycle')\n",
    "    parser.add_argument('--identity_weight', type=int, default=10, help='Weight for Identity')\n",
    "    parser.add_argument('--cam_weight', type=int, default=1000, help='Weight for CAM')\n",
    "\n",
    "    parser.add_argument('--ch', type=int, default=64, help='base channel number per layer')\n",
    "    parser.add_argument('--n_res', type=int, default=4, help='The number of resblock')\n",
    "    parser.add_argument('--n_dis', type=int, default=6, help='The number of discriminator layer')\n",
    "\n",
    "#     parser.add_argument('--img_size', type=int, default=256, help='The size of image')\n",
    "    parser.add_argument('--img_size', type=int, default=128, help='The size of image')\n",
    "\n",
    "    parser.add_argument('--img_ch', type=int, default=3, help='The size of image channel')\n",
    "\n",
    "    parser.add_argument('--result_dir', type=str, default='results', help='Directory name to save the results')\n",
    "    parser.add_argument('--device', type=str, default='cuda: 4, cuda: 5, cuda: 6, cuda: 7', choices=['cpu', 'cuda'], help='Set gpu mode; [cpu, cuda]')\n",
    "    parser.add_argument('--benchmark_flag', type=str2bool, default=False)\n",
    "    parser.add_argument('--resume', type=str2bool, default=False)\n",
    "\n",
    "    return check_args(parser.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"checking arguments\"\"\"\n",
    "def check_args(args):\n",
    "    # --result_dir\n",
    "    check_folder(os.path.join(args.result_dir, args.dataset, 'model'))\n",
    "    check_folder(os.path.join(args.result_dir, args.dataset, 'img'))\n",
    "    check_folder(os.path.join(args.result_dir, args.dataset, 'test'))\n",
    "\n",
    "    # --epoch\n",
    "    try:\n",
    "        assert args.epoch >= 1\n",
    "    except:\n",
    "        print('number of epochs must be larger than or equal to one')\n",
    "\n",
    "    # --batch_size\n",
    "    try:\n",
    "        assert args.batch_size >= 1\n",
    "    except:\n",
    "        print('batch size must be larger than or equal to one')\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.argv=['']; del sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of epochs must be larger than or equal to one\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adv_weight=1, batch_size=1, benchmark_flag=False, cam_weight=1000, ch=64, cycle_weight=10, dataset='selfie2anime', decay_flag=True, device='cuda: 4, cuda: 5, cuda: 6, cuda: 7', identity_weight=10, img_ch=3, img_size=128, iteration=1000000, light=False, lr=0.0001, n_dis=6, n_res=4, phase='train', print_freq=10, result_dir='results', resume=False, save_freq=10, weight_decay=0.0001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##### Information #####\n",
      "# light :  False\n",
      "# dataset :  selfie2anime\n",
      "# batch_size :  1\n",
      "# iteration per epoch :  1000000\n",
      "\n",
      "##### Generator #####\n",
      "# residual blocks :  4\n",
      "\n",
      "##### Discriminator #####\n",
      "# discriminator layer :  6\n",
      "\n",
      "##### Weight #####\n",
      "# adv_weight :  1\n",
      "# cycle_weight :  10\n",
      "# identity_weight :  10\n",
      "# cam_weight :  1000\n"
     ]
    }
   ],
   "source": [
    "# args = parse_args()\n",
    "# if args is None:\n",
    "#   exit()\n",
    "\n",
    "# open session\n",
    "gan = UGATIT(args)\n",
    "\n",
    "# build graph\n",
    "gan.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1/1000000] time: 3.6669 d_loss: 7.70937443, g_loss: 5265.09472656\n",
      "[    2/1000000] time: 4.4379 d_loss: 4.88352489, g_loss: 4759.46337891\n",
      "[    3/1000000] time: 5.1851 d_loss: 5.07710505, g_loss: 4469.79248047\n",
      "[    4/1000000] time: 6.1055 d_loss: 5.12592125, g_loss: 3558.25537109\n",
      "[    5/1000000] time: 6.8023 d_loss: 7.72441626, g_loss: 3040.32055664\n",
      "[    6/1000000] time: 7.4776 d_loss: 5.76809263, g_loss: 2483.96166992\n",
      "[    7/1000000] time: 8.2045 d_loss: 5.59306049, g_loss: 5926.31787109\n",
      "[    8/1000000] time: 8.8941 d_loss: 4.95289803, g_loss: 3178.44238281\n",
      "[    9/1000000] time: 9.6727 d_loss: 4.76830578, g_loss: 3577.14843750\n",
      "[   10/1000000] time: 10.5735 d_loss: 4.88008785, g_loss: 3326.02197266\n"
     ]
    }
   ],
   "source": [
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.load_own_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.genA2B\n",
    "# gan.genB2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.genA2B.eval(), self.genB2A.eval()\n",
    "for n, (real_A, _) in enumerate(self.testA_loader):\n",
    "    real_A = real_A.to(self.device)\n",
    "\n",
    "    fake_A2B, _, fake_A2B_heatmap = self.genA2B(real_A)\n",
    "\n",
    "    fake_A2B2A, _, fake_A2B2A_heatmap = self.genB2A(fake_A2B)\n",
    "\n",
    "    fake_A2A, _, fake_A2A_heatmap = self.genB2A(real_A)\n",
    "\n",
    "    A2B = np.concatenate((RGB2BGR(tensor2numpy(denorm(real_A[0]))),\n",
    "                          cam(tensor2numpy(fake_A2A_heatmap[0]), self.img_size),\n",
    "                          RGB2BGR(tensor2numpy(denorm(fake_A2A[0]))),\n",
    "                          cam(tensor2numpy(fake_A2B_heatmap[0]), self.img_size),\n",
    "                          RGB2BGR(tensor2numpy(denorm(fake_A2B[0]))),\n",
    "                          cam(tensor2numpy(fake_A2B2A_heatmap[0]), self.img_size),\n",
    "                          RGB2BGR(tensor2numpy(denorm(fake_A2B2A[0])))), 0)\n",
    "\n",
    "    cv2.imwrite(os.path.join(self.result_dir, self.dataset, 'test', 'A2B_%d.png' % (n + 1)), A2B * 255.0)\n",
    "\n",
    "for n, (real_B, _) in enumerate(self.testB_loader):\n",
    "    real_B = real_B.to(self.device)\n",
    "\n",
    "    fake_B2A, _, fake_B2A_heatmap = self.genB2A(real_B)\n",
    "\n",
    "    fake_B2A2B, _, fake_B2A2B_heatmap = self.genA2B(fake_B2A)\n",
    "\n",
    "    fake_B2B, _, fake_B2B_heatmap = self.genA2B(real_B)\n",
    "\n",
    "    B2A = np.concatenate((RGB2BGR(tensor2numpy(denorm(real_B[0]))),\n",
    "                          cam(tensor2numpy(fake_B2B_heatmap[0]), self.img_size),\n",
    "                          RGB2BGR(tensor2numpy(denorm(fake_B2B[0]))),\n",
    "                          cam(tensor2numpy(fake_B2A_heatmap[0]), self.img_size),\n",
    "                          RGB2BGR(tensor2numpy(denorm(fake_B2A[0]))),\n",
    "                          cam(tensor2numpy(fake_B2A2B_heatmap[0]), self.img_size),\n",
    "                          RGB2BGR(tensor2numpy(denorm(fake_B2A2B[0])))), 0)\n",
    "\n",
    "    cv2.imwrite(os.path.join(self.result_dir, self.dataset, 'test', 'B2A_%d.png' % (n + 1)), B2A * 255.0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
